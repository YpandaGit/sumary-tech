## 业务场景简单说明
* 角色定义

1. 消费者：负责接收数据并入库
2. mq：发送需要入库的数据

* 简化数据表格

|字段|说明|
|-|-|
|id|主键（接收方入库时自动生成）|
|phone|手机号|
|userId|用户id|
|other|其他数据，暂时忽略|


* 解释
mq发送的消息里包括了phone与userId以及其他数据，消费者扶着入库数据并且保证phone与userId都存在时则更新其他数据，否则插入数据。

## 问题代码

* 伪代码
```java
User user = new User(phone,userId);
// 判断是否已插入
if(null == userMapper.findByPhoneAndUserId(phone,userId)){
// 没有该数据则插入
userMapper.insert(user);
}else{
user = userMapper.findByPhoneAndUserId(phone,userId);
// 设置接收到的其他属性
user.seOther(other);
// 更新
userMapper.update(user);
}
```

> 以上代码在开发自测和测试中都没有发生问题，但是在生产环境中则发现了大量重复数据，示例：

|id|phone|userId|
|-|-|-|
|1|12345678|222|
|2|12345678|222|
|3|12345678|222|
|4|12345678|222|

## 解决方案
还好刚上线就发现了这个问题，不然麻烦就大了。既然发现了，那么就是解决方案了。

### 数据库增加联合唯一索引
从结果上保证了数据的唯一性，不会再有重复数据，也是最简单的一个。但是缺点也很明显，虽然数据不会重复，但是消息的更新却很有可能失败，在比如在上述代码中，同一个phone和userId的两条消息同时进入`if`代码块,刚好该phone与userId并没有入库，那么势必有一条数据会被被丢弃（即插入失败），相当于没消费到该消息。

### 通过redis实现分布式锁保证数据唯一
redis的setnx能够很简单的实现分布式锁来保证数据的唯一性。没有取到锁的消息就直接放弃。

> 都只是保证了数据的不重复，直接放弃了可能需要更新的数据。根据不同的业务场景可以自行选择处理方案。

## 如何使得插入失败的数据不丢失
### MQ消息回退
在添加联合索引的基础上，在代码层面增加MQ消息确认机制，捕获到插入失败的异常则将该消息重新入队。可以保证每条消息都能被消费到。

## 总结
这次还好问题发现的早，所以能够毫不费力的改改代码重新上线，不然后面数据的清洗会让人非常的崩溃（表之间还有外键关系）。
自身完全没有考虑到可能会同时处理者同一个phone和userId的不同消息，以后对于业务的理解还需要更加的严谨。